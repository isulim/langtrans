{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Experiments with libraries",
   "id": "7723073d9380165e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 1. Language detection",
   "id": "19723c503172873a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-26T20:27:29.327543Z",
     "start_time": "2024-08-26T20:27:29.324673Z"
    }
   },
   "cell_type": "code",
   "source": "LANGUAGES = [\"de\", \"en\", \"el\", \"es\", \"fr\", \"it\", \"pl\", \"pt\", \"ro\", \"nl\"]",
   "id": "initial_id",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-26T20:27:29.392105Z",
     "start_time": "2024-08-26T20:27:29.328501Z"
    }
   },
   "cell_type": "code",
   "source": "import py3langid as langid",
   "id": "d7ccdaeba2bba742",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-26T20:27:29.442166Z",
     "start_time": "2024-08-26T20:27:29.392905Z"
    }
   },
   "cell_type": "code",
   "source": [
    "text = \"This is a test\"\n",
    "langid.classify(text)"
   ],
   "id": "5f961ed7c01c5268",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('en', np.float32(-54.413105))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-26T20:27:29.444573Z",
     "start_time": "2024-08-26T20:27:29.442938Z"
    }
   },
   "cell_type": "code",
   "source": "from py3langid.langid import LanguageIdentifier, MODEL_FILE\n",
   "id": "3e024267e3421e56",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-26T20:27:29.493280Z",
     "start_time": "2024-08-26T20:27:29.446431Z"
    }
   },
   "cell_type": "code",
   "source": "identifier = LanguageIdentifier.from_pickled_model(MODEL_FILE, norm_probs=True)",
   "id": "c4be9c4bfd5264e6",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-26T20:27:29.495869Z",
     "start_time": "2024-08-26T20:27:29.493864Z"
    }
   },
   "cell_type": "code",
   "source": "identifier.set_languages(LANGUAGES)",
   "id": "4fd8b4f15a8e9858",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-26T20:27:29.498849Z",
     "start_time": "2024-08-26T20:27:29.496533Z"
    }
   },
   "cell_type": "code",
   "source": "identifier.classify(\"This is a test\")",
   "id": "170f2e0fc92453f7",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('en', np.float32(1.0))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-26T20:27:29.502085Z",
     "start_time": "2024-08-26T20:27:29.499626Z"
    }
   },
   "cell_type": "code",
   "source": "identifier.classify(\"Das ist ein Test\")",
   "id": "5d04404571341351",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('de', np.float32(1.0))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-26T20:27:29.504742Z",
     "start_time": "2024-08-26T20:27:29.502694Z"
    }
   },
   "cell_type": "code",
   "source": "identifier.classify(\"Esto es una prueba\")",
   "id": "4a2911a7be27203c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('es', np.float32(1.0))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-26T20:27:29.507479Z",
     "start_time": "2024-08-26T20:27:29.505233Z"
    }
   },
   "cell_type": "code",
   "source": "identifier.classify(\"Il s'agit d'un test\")",
   "id": "ffe548c67edac07e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('fr', np.float32(0.9990453))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-26T20:27:29.510549Z",
     "start_time": "2024-08-26T20:27:29.508181Z"
    }
   },
   "cell_type": "code",
   "source": "identifier.classify(\"Dit is een test\")",
   "id": "57f1046be5ce46d4",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('nl', np.float32(0.9885795))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-26T20:27:29.513034Z",
     "start_time": "2024-08-26T20:27:29.511142Z"
    }
   },
   "cell_type": "code",
   "source": "identifier.classify(\"Questo è un test\")",
   "id": "b49ce218c87c1c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('it', np.float32(1.0))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-26T20:27:29.515647Z",
     "start_time": "2024-08-26T20:27:29.513524Z"
    }
   },
   "cell_type": "code",
   "source": "identifier.classify(\"To jest test\")",
   "id": "e63be9a6b145bed3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('pl', np.float32(0.99995136))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-26T20:27:29.520286Z",
     "start_time": "2024-08-26T20:27:29.517798Z"
    }
   },
   "cell_type": "code",
   "source": "identifier.classify(\"Aceasta este o testare\")",
   "id": "10d1a8a1bdb26088",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('ro', np.float32(0.9973043))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-26T20:27:29.523056Z",
     "start_time": "2024-08-26T20:27:29.520879Z"
    }
   },
   "cell_type": "code",
   "source": "identifier.classify(\"Αυτό είναι ένα τεστ\")",
   "id": "63096c93dea8a333",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'el'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2. Text translation",
   "id": "78a5d90dc5e5c0e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-26T20:27:29.525522Z",
     "start_time": "2024-08-26T20:27:29.523816Z"
    }
   },
   "cell_type": "code",
   "source": [
    "MODEL_NAME = \"facebook/m2m100_418M\"\n",
    "FILENAME = \"m2m100_418M\""
   ],
   "id": "16d02185be67cf87",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-26T20:27:29.527652Z",
     "start_time": "2024-08-26T20:27:29.526159Z"
    }
   },
   "cell_type": "code",
   "source": "from pathlib import Path",
   "id": "3f8380b58e75d516",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-26T20:27:34.948376Z",
     "start_time": "2024-08-26T20:27:29.528182Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import M2M100ForConditionalGeneration, M2M100Tokenizer\n",
    "tokenizer = M2M100Tokenizer.from_pretrained(MODEL_NAME)\n",
    "model = M2M100ForConditionalGeneration.from_pretrained(MODEL_NAME)\n",
    "local_model_path = Path(f\"models/{FILENAME}\")\n",
    "model.save_pretrained(local_model_path)\n"
   ],
   "id": "fd711effa6369ffd",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/isulim/PycharmProjects/ai-python-engineer-challenge-igor-sulim/.venv/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 200, 'early_stopping': True, 'num_beams': 5}\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-26T20:28:19.602474Z",
     "start_time": "2024-08-26T20:28:19.599921Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tokenizer.src_lang = \"en\"\n",
    "inputs = tokenizer(\"Hello, my dog is cute\", return_tensors=\"pt\").input_ids"
   ],
   "id": "525edbda7d740afa",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-26T20:28:20.396863Z",
     "start_time": "2024-08-26T20:28:20.183909Z"
    }
   },
   "cell_type": "code",
   "source": [
    "outputs = model.generate(inputs, forced_bos_token_id=tokenizer.lang_code_to_id[\"el\"])\n",
    "tokenizer.decode(outputs[0], skip_special_tokens=True)"
   ],
   "id": "10658d96aa2c201e",
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "File \u001B[0;32m~/PycharmProjects/ai-python-engineer-challenge-igor-sulim/.venv/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:270\u001B[0m, in \u001B[0;36mBatchEncoding.__getattr__\u001B[0;34m(self, item)\u001B[0m\n\u001B[1;32m    269\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 270\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdata\u001B[49m\u001B[43m[\u001B[49m\u001B[43mitem\u001B[49m\u001B[43m]\u001B[49m\n\u001B[1;32m    271\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m:\n",
      "\u001B[0;31mKeyError\u001B[0m: 'shape'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[28], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m outputs \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgenerate\u001B[49m\u001B[43m(\u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mforced_bos_token_id\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtokenizer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlang_code_to_id\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mel\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      2\u001B[0m tokenizer\u001B[38;5;241m.\u001B[39mdecode(outputs[\u001B[38;5;241m0\u001B[39m], skip_special_tokens\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "File \u001B[0;32m~/PycharmProjects/ai-python-engineer-challenge-igor-sulim/.venv/lib/python3.12/site-packages/torch/utils/_contextlib.py:116\u001B[0m, in \u001B[0;36mcontext_decorator.<locals>.decorate_context\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    113\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(func)\n\u001B[1;32m    114\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdecorate_context\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m    115\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m ctx_factory():\n\u001B[0;32m--> 116\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/ai-python-engineer-challenge-igor-sulim/.venv/lib/python3.12/site-packages/transformers/generation/utils.py:1710\u001B[0m, in \u001B[0;36mGenerationMixin.generate\u001B[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001B[0m\n\u001B[1;32m   1706\u001B[0m \u001B[38;5;66;03m# 3. Define model inputs\u001B[39;00m\n\u001B[1;32m   1707\u001B[0m inputs_tensor, model_input_name, model_kwargs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_prepare_model_inputs(\n\u001B[1;32m   1708\u001B[0m     inputs, generation_config\u001B[38;5;241m.\u001B[39mbos_token_id, model_kwargs\n\u001B[1;32m   1709\u001B[0m )\n\u001B[0;32m-> 1710\u001B[0m batch_size \u001B[38;5;241m=\u001B[39m \u001B[43minputs_tensor\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mshape\u001B[49m[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m   1712\u001B[0m device \u001B[38;5;241m=\u001B[39m inputs_tensor\u001B[38;5;241m.\u001B[39mdevice\n\u001B[1;32m   1713\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_prepare_special_tokens(generation_config, kwargs_has_attention_mask, device\u001B[38;5;241m=\u001B[39mdevice)\n",
      "File \u001B[0;32m~/PycharmProjects/ai-python-engineer-challenge-igor-sulim/.venv/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:272\u001B[0m, in \u001B[0;36mBatchEncoding.__getattr__\u001B[0;34m(self, item)\u001B[0m\n\u001B[1;32m    270\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdata[item]\n\u001B[1;32m    271\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m:\n\u001B[0;32m--> 272\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAttributeError\u001B[39;00m\n",
      "\u001B[0;31mAttributeError\u001B[0m: "
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-26T20:27:38.395147Z",
     "start_time": "2024-08-26T20:27:37.011387Z"
    }
   },
   "cell_type": "code",
   "source": [
    "outputs = model.generate(inputs, forced_bos_token_id=tokenizer.lang_code_to_id[\"pl\"])\n",
    "tokenizer.decode(outputs[0], skip_special_tokens=True)"
   ],
   "id": "56cfff6d430e412",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Cześć, mój pies jest miły'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-26T20:27:39.802169Z",
     "start_time": "2024-08-26T20:27:38.396009Z"
    }
   },
   "cell_type": "code",
   "source": [
    "outputs = model.generate(inputs, forced_bos_token_id=tokenizer.lang_code_to_id[\"es\"])\n",
    "tokenizer.decode(outputs[0], skip_special_tokens=True)"
   ],
   "id": "9b6690d2b3e5b7da",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hola, mi perro es hermoso'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-26T20:27:40.792061Z",
     "start_time": "2024-08-26T20:27:39.803164Z"
    }
   },
   "cell_type": "code",
   "source": [
    "outputs = model.generate(inputs, forced_bos_token_id=tokenizer.lang_code_to_id[\"de\"])\n",
    "tokenizer.decode(outputs[0], skip_special_tokens=True)"
   ],
   "id": "5603764f1a7b8a8e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hallo, mein Hund ist schön'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-26T20:27:40.794469Z",
     "start_time": "2024-08-26T20:27:40.792924Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "593c23f5fd2868aa",
   "outputs": [],
   "execution_count": 23
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
